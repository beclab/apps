metadata:
  title: Faster Whisper For Cluster
  description: Faster Whisper transcription with CTranslate2
spec:
  fullDescription: |
    ## IMPORTANT NOTE ##
    Please note that this is a cluster-scoped app, you will need the corresponding client app to use it.

    ## OVERVIEW ##
    faster-whisper-server uses faster-whisper as it's backend, and is able to provide OpenAI API compatible transcription server

    faster-whisper is a reimplementation of OpenAI's Whisper model using CTranslate2, which is a fast inference engine for Transformer models.
    This implementation is up to 4 times faster than openai/whisper for the same accuracy while using less memory. The efficiency can be further improved with 8-bit quantization on both CPU and GPU.

    Features:
    GPU and CPU support.
    Configurable through environment variables (see config.py).
    OpenAI API compatible.

    Find more about Faster Whisper at: https://github.com/SYSTRAN/faster-whisper
  upgradeDescription: |
    fix: lint errors

    View full release note here: https://github.com/fedirz/faster-whisper-server/releases/tag/v0.3.0
