olaresManifest.version: '0.10.0'
olaresManifest.type: app
metadata:
  name: hunyuan3d
  description: A Unified Framework for Text-to-3D and Image-to-3D Generation
  icon: https://file.bttcdn.com/appstore/hunyuan3d/logo.png
  appid: hunyuan3d
  version: '1.0.2'
  title: Hunyuan3D For Cluster
  categories:
  - Creativity
  - Utilities
permission:
  appData: true
  appCache: true
  userData:
  - Home
spec:
  promoteImage:
  - https://file.bttcdn.com/appstore/hunyuan3d/teaser.jpg
  versionName: '1.0.0'
  fullDescription: |
    ## IMPORTANT NOTE ##
    Please note that this is a cluster-scoped app, you will need the corresponding client app to use it.

    ## OVERVIEW ##
    Tencent Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation

    Features: 
    - First open-source model that supports text-and image-conditioned 3d generation both
    - With strong generalization ability and controllability, our model can reconstruct objects of various scales, from large structures like buildings to small items like tools and plants.
    - End-to-end generation within 10 seconds,including mesh and texture extraction.
    
    Abstract: 
    While 3D generative models have greatly improved artists' workflows, the existing diffusion models for 3D generation suffer from slow generation and poor generalization. To address this issue, we propose a two-stage approach named Hunyuan3D-1.0 including a lite version and a standard version, that both support text- and image-conditioned generation.

    In the first stage, we employ a multi-view diffusion model that efficiently generates multi-view RGB in approximately 4 seconds. These multi-view images capture rich details of the 3D asset from different viewpoints, relaxing the tasks from single-view to multi-view reconstruction. In the second stage, we introduce a feed-forward reconstruction model that rapidly and faithfully reconstructs the 3D asset given the generated multi-view images in approximately 7 seconds. The reconstruction network learns to handle noises and in-consistency introduced by the multi-view diffusion and leverages the available information from the condition image to efficiently recover the 3D structure.

    Our framework involves the text-to-image model, i.e., Hunyuan-DiT, making it a unified framework to support both text- and image-conditioned 3D generation. Our standard version has 3x more parameters than our lite and other existing model. Our Hunyuan3D-1.0 achieves an impressive balance between speed and quality, significantly reducing generation time while maintaining the quality and diversity of the produced assets.
    
  developer: Tencent
  website: https://3d.hunyuan.tencent.com/
  sourceCode: https://github.com/Tencent/Hunyuan3D-1
  submitter: Olares
  locale:
  - en-US
  - zh-CN
  requiredMemory: 3Gi
  limitedMemory: 40Gi
  requiredDisk: 128Mi
  limitedDisk: 256Mi
  requiredCpu: 0.5
  limitedCpu: 8
  requiredGpu: 24Gi
  limitedGpu: 80Gi
  doc: https://github.com/Tencent/Hunyuan3D-1?tab=readme-ov-file
  license:
  - text: TENCENT HUNYUAN NON-COMMERCIAL
    url: https://github.com/Tencent/Hunyuan3D-1?tab=License-1-ov-file#readme
  onlyAdmin: true
  supportArch:
  - amd64
options:
  dependencies:
  - name: olares
    type: system
    version: '>=1.10.1-0'
  appScope:
    clusterScoped: true
    appRef:
    - hunyuan3dclient
entrances:
- name: hunyuan3d
  port: 8080
  host: hunyuan3d
  title: Hunyuan3D For Cluster
  icon: https://file.bttcdn.com/appstore/hunyuan3d/logo.png
  authLevel: private
  invisible: true