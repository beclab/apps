metadata:
  title: Yarn Mistral 7B Q4
  description: A state-of-the-art language model for long context.
spec:
  fullDescription: |
    Nous-Yarn-Mistral-7b-128k is a state-of-the-art language model for long context, further pretrained on long context data for 1500 steps using the YaRN extension method.

    It is an extension of Mistral-7B-v0.1 and supports a 128k token context window.

    Model Name: Yarn Mistral 7B 128K
    Model Creator: NousResearch
    Model Type: mistral
    Quantized by: TheBloke
    Library Name: transformers

    Base model: NousResearch/Yarn-Mistral-7b-128k

    Datasets:
    - emozilla/yarn-train-tokenized-16k-mistral
  upgradeDescription: |
    Update featuredImage
