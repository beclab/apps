---
olaresManifest.version: '0.10.0'
olaresManifest.type: app
apiVersion: 'v2'
metadata:
  name: ollamallava1613bv2
  icon: https://app.cdn.olares.com/appstore/llm/ollama/multimodal/Llava-1.6-13b.png
  description: A novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding.
  appid: ollamallava1613bv2
  title: LLaVA 1.6 13B (Ollama)
  version: '1.0.8'
  categories:
    - AI
sharedEntrances:
  - name: ollamallava1613bv2
    host: sharedentrances-api
    port: 0
    tile: LLaVA 1.6 13B
    invisible: true
    authLevel: internal
    icon: https://app.cdn.olares.com/appstore/llm/ollama/multimodal/Llava-1.6-13b.png
entrances:
  - name: ollamaclient
    port: 8080
    host: ollamaclient
    title: LLaVA 1.6 13B
    icon: https://app.cdn.olares.com/appstore/llm/ollama/multimodal/Llava-1.6-13b.png
    openMethod: window
    authLevel: internal
spec:
  versionName: 'llava:13b-v1.6-vicuna-q4_0'
  fullDescription: |
    ## IMPORTANT NOTE ##
    This is a shared app. Once installed by the Olares Admin, all users in the cluster can use it through reference app.

    ## MODEL OVERVIEW ##
    LLaVA is a multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding, achieving impressive chat capabilities mimicking spirits of the multimodal GPT-4.

    It is an auto-regressive language model, based on the transformer architecture. Base LLM: lmsys/vicuna-13b-v1.5

    # New in LLaVA 1.6:
    - Increasing the input image resolution to up to 4x more pixels, supporting 672x672, 336x1344, 1344x336 resolutions.
    - Better visual reasoning and OCR capability with an improved visual instruction tuning data mixture.
    - Better visual conversation for more scenarios, covering different applications.
    - Better world knowledge and logical reasoning.

  developer: haotian-liu
  website: https://llava-vl.github.io/
  sourceCode: https://github.com/haotian-liu/LLaVA
  submitter: Olares
  locale:
    - en-US
    - zh-CN
  license:
    - text: LLAMA 2 COMMUNITY LICENSE AGREEMENT
      url: https://ollama.com/library/llava:13b/blobs/41774062cd34

  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
  limitedCpu: 6200m
  requiredCpu: 150m
  requiredDisk: 50Mi
  limitedDisk: 500Gi
  limitedMemory: 40Gi
  requiredMemory: 4200Mi
  requiredGpu: 0
  limitedGpu: 16Gi
  {{- else }}
  requiredMemory: 64Mi
  limitedMemory: 800Mi
  requiredDisk: 50Mi
  limitedDisk: 200Mi
  requiredCpu: 10m
  limitedCpu: 800m
  {{- end }}

  supportArch:
    - amd64
    - arm64
  subCharts:
  - name: ollamallava1613bv2server
    shared: true
  - name: ollamallava1613bv2
permission:
  appData: true
  appCache: true
  userData:
    - Home/Ollama
options:
  apiTimeout: 0
  appScope:
  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
    clusterScoped: true
    appRef:
      - ollamallava1613bv2
  {{- else }}
    clusterScoped: false
  {{- end }}
  dependencies:
    - name: olares
      version: '>=1.12.3-0'
      type: system
  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
  {{- else }}
    - name: ollamallava1613bv2
      type: application
      version: '>=1.0.1'
      mandatory: true
  {{- end }}