{{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
{{- $ollamaclientDomainENV := split "," .Values.domain.ollamaclient -}}
{{- $ollamaclientDomain := index $ollamaclientDomainENV "_0" -}}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    io.kompose.service: ollama
  name: ollama
  namespace: "{{ .Release.Namespace }}"
  annotations:
    applications.app.bytetrade.io/gpu-inject: "true"
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: ollama
  strategy:
    type: Recreate
  template:
    metadata:
      creationTimestamp: null
      labels:
        io.kompose.network/chrome-default: "true"
        io.kompose.service: ollama
    spec:
      containers:
        - name: ollama
          image: "docker.io/beclab/ollama-ollama:0.15.6"
{{- with .Values.olaresEnv }}
{{- if and .KEEP_ALIVE (eq (lower (toString .KEEP_ALIVE)) "true") }}
          command:
            - sh
            - '-c'
            - |
              echo "Starting Ollama server..."
              ollama serve &
              SERVER_PID=$!
              until ollama list > /dev/null 2>&1; do
                sleep 1
              done
              echo "Ollama server is ready. Preloading model..."
              START_TIME=$(date +%s)
              ollama run ${MODEL_NAME} "Hello"
              END_TIME=$(date +%s)
              ELAPSED=$((END_TIME - START_TIME))
              echo "Model preloading completed in ${ELAPSED} seconds"
              wait $SERVER_PID
{{- end }}
{{- end }}
          envFrom:
            - configMapRef:
                name: ollama-env
          env:
{{- with .Values.olaresEnv }}
{{- if and .KEEP_ALIVE (eq (lower (toString .KEEP_ALIVE)) "true") }}
            - name: OLLAMA_KEEP_ALIVE
              value: "-1"
{{- end }}
{{- end }}
          ports:
            - containerPort: 11434
          livenessProbe:
            httpGet:
              path: /
              port: 11434
              scheme: HTTP
            initialDelaySeconds: 30
            timeoutSeconds: 60
            periodSeconds: 60
            successThreshold: 1
            failureThreshold: 10
          startupProbe:
            tcpSocket:
              port: 11434
            timeoutSeconds: 5
            periodSeconds: 10
            successThreshold: 1
            failureThreshold: 30
          resources:
            limits:
              cpu: "4"
              memory: 30Gi
            requests:
              cpu: 50m
              memory: 4Gi
          volumeMounts:
            - mountPath: "/root/.ollama"
              name: data
        - name: api
          image: "docker.io/beclab/harveyff-olares-ollama:v0.1.2"
          env:
            - name: PGID
              value: "1000"
            - name: PUID
              value: "1000"
            - name: TZ
              value: Etc/UTC
            - name: DISPLAY
              value: ":0"
            - name: OLLAMA_MODEL
              valueFrom:
                configMapKeyRef:
                  name: ollama-env
                  key: MODEL_NAME
            - name: OLLAMA_URL
              value: "http://localhost:11434"
            - name: APP_URL
              value: "https://{{ $ollamaclientDomain }}"
          resources:
            requests:
              cpu: 300m
              memory: 200Mi
            limits:
              cpu: 1000m
              memory: 2Gi
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
      volumes:
        - name: data
          hostPath:
            path: "{{ .Values.userspace.userData }}/Ollama/{{ .Release.Name }}"
            type: DirectoryOrCreate
      restartPolicy: Always
status: {}
---
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    io.kompose.service: api
  name: api
  namespace: "{{ .Release.Namespace }}"
spec:
  ports:
    - name: "api"
      port: 8081
      targetPort: 8080
  selector:
    io.kompose.service: ollama
status:
  loadBalancer: {}
  
---
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    io.kompose.service: api
  name: sharedentrances-api
  namespace: "{{ .Release.Namespace }}"
spec:
  ports:
    - name: "api"
      port: 80
      targetPort: 8080
  selector:
    io.kompose.service: ollama
status:
  loadBalancer: {}
{{- end }}