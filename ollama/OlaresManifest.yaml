olaresManifest.version: '0.8.1'
olaresManifest.type: app
metadata:
  name: ollama
  icon: https://file.bttcdn.com/appstore/ollama/icon.png
  description: Get up and running with large language models.
  appid: ollama
  title: Ollama
  version: '1.0.15'
  categories:
  - Productivity
entrances:
- name: terminal
  port: 80
  host: terminal
  title: Ollama
  icon: https://file.bttcdn.com/appstore/ollama/icon.png
  openMethod: default
# - authLevel: private
#   host: ollama
#   icon: https://file.bttcdn.com/appstore/ollama/icon.png
#   name: ollama
#   openMethod: default
#   port: 11434
#   title: Ollama
#   invisible: true
- authLevel: internal
  host: ollamaclient
  icon: https://file.bttcdn.com/appstore/ollama/icon.png
  name: ollamaclient
  openMethod: default
  port: 8080
  title: Ollama
  invisible: true
spec:
  versionName: '0.5.12'
  featuredImage: https://file.bttcdn.com/appstore/ollama/1.webp
  promoteImage:
  - https://file.bttcdn.com/appstore/ollama/1.webp
  - https://file.bttcdn.com/appstore/ollama/2.webp
  - https://file.bttcdn.com/appstore/ollama/3.webp
  fullDescription: |
    ## IMPORTANT NOTE ##
    Please note that this is a cluster-scoped app, you will need the corresponding app to use it.

    ## OVERVIEW ##
    Ollama is a user-friendly interface for running large language models (LLMs) locally. It is a valuable tool for researchers, developers, and anyone who wants to experiment with language models. With Ollama, you can easily download and run LLMs, customize and create your own, and chat with your LLMs using files on your device.

    Ollama supports a wide range of models, including:
    - Llama 3	8B
    - Llama 3	70B
    - Phi 3 Mini	3.8B
    - Phi 3 Medium	14B
    - Gemma 2	9B
    - Gemma 2	27B
    - Mistral	7B
    - Moondream 2	1.4B
    - Neural Chat	7B
    - Starling	7B
    - Code Llama	7B
    - Llama 2 Uncensored	7B
    - LLaVA	7B
    - Solar	10.7B

  upgradeDescription: |
    Upgrade App Version to v0.5.12
    Allow Cross-Origin Access

    # New models
    Perplexity R1 1776: A version of the DeepSeek-R1 model that has been post trained to remove its refusal to respond to some sensitive topics.

    # What's Changed
    The OpenAI-compatible API will now return tool_calls if the model called a tool
    Performance on certain Intel Xeon processors should now be restored
    Fixed permission denied issues after installing Ollama on Linux
    Fixed issue where additional CPU libraries were included in the arm64 Linux install
    The progress bar will no longer flicker when running ollama pull
    Fixed issue where running a model would fail on Linux if Ollama was installed in a path with UTF-8 characters
    X-Stainless-Timeout will now be accepted as a header in the OpenAI API endpoints

    Get full release note at: https://github.com/ollama/ollama/releases/tag/v0.5.12
    
  developer: ollama
  website: https://ollama.com/
  sourceCode: https://github.com/ollama/ollama
  submitter: Olares
  locale:
  - en-US
  - zh-CN
  doc: https://github.com/ollama/ollama/tree/main/docs
  license:
  - text: MIT
    url: https://github.com/ollama/ollama#MIT-1-ov-file
  limitedCpu: 6200m
  requiredCpu: 150m
  requiredDisk: 50Mi
  limitedDisk: 500Gi
  limitedMemory: 18200Mi
  requiredMemory: 4200Mi
  requiredGpu: 0
  limitedGpu: 16Gi
  supportArch:
  - amd64
  - arm64
  onlyAdmin: true
permission:
  appData: true
  appCache: true
options:
  apiTimeout: 0
  dependencies:
  - name: olares
    version: '>=1.11.0-0'
    type: system
  appScope:
    clusterScoped: true
    appRef:
    - openwebui
    - perplexica
    - n8n
    - ragflow
    - lobechat
