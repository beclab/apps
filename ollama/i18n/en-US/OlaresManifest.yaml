metadata:
  title: Ollama
  description: Get up and running with large language models.

spec:
  fullDescription: |
    ## IMPORTANT NOTE ##
    This is a shared app. Once installed by the Olares Admin, all users in the cluster can use it through reference app.

    ## OVERVIEW ##
    Ollama is a user-friendly interface for running large language models (LLMs) locally. It is a valuable tool for researchers, developers, and anyone who wants to experiment with language models. With Ollama, you can easily download and run LLMs, customize and create your own, and chat with your LLMs using files on your device.

    Ollama supports a wide range of models, including:
    - Llama 3 8B
    - Llama 3 70B
    - Phi 3 Mini 3.8B
    - Phi 3 Medium 14B
    - Gemma 2 9B
    - Gemma 2 27B
    - Mistral 7B
    - Moondream 2 1.4B
    - Neural Chat 7B
    - Starling 7B
    - Code Llama 7B
    - Llama 2 Uncensored 7B
    - LLaVA 7B
    - Solar 10.7B

  upgradeDescription: |
    Upgrade Ollama version to v0.12.7

    # New models
    - Qwen3-VL: Qwen3-VL is now available in all parameter sizes ranging from 2B to 235B
    - MiniMax-M2: a 230 Billion parameter model built for coding & agentic workflows available on Ollama's cloud

    # What's Changed
    - Model load failures now include more information on Windows
    - Fixed embedding results being incorrect when running embeddinggemma
    - Fixed gemma3n on Vulkan backend
    - Increased time allocated for ROCm to discover devices
    - Fixed truncation error when generating embeddings
    - Fixed request status code when running cloud models
    - The OpenAI-compatible /v1/embeddings endpoint now supports encoding_format parameter
    - Ollama will now parse tool calls that don't conform to {"name": name, "arguments": args} (thanks @rick-github!)
    - Fixed prompt processing reporting in the llama runner
    - Increase speed when scheduling models
    - Fixed issue where FROM <model> would not inherit RENDERER or PARSER commands

    Get full release note at: https://github.com/ollama/ollama/releases/tag/v0.12.7