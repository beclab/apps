metadata:
  title: Ollama
  description: Get up and running with large language models.
spec:
  fullDescription: |
    ## IMPORTANT NOTE ##
    This is a shared app. Once installed by the Olares Admin, all users in the cluster can use it through reference app.

    ## OVERVIEW ##
    Ollama is a user-friendly interface for running large language models (LLMs) locally. It is a valuable tool for researchers, developers, and anyone who wants to experiment with language models. With Ollama, you can easily download and run LLMs, customize and create your own, and chat with your LLMs using files on your device.

    Ollama supports a wide range of models, including:
    - Llama 3	8B
    - Llama 3	70B
    - Phi 3 Mini	3.8B
    - Phi 3 Medium	14B
    - Gemma 2	9B
    - Gemma 2	27B
    - Mistral	7B
    - Moondream 2	1.4B
    - Neural Chat	7B
    - Starling	7B
    - Code Llama	7B
    - Llama 2 Uncensored	7B
    - LLaVA	7B
    - Solar	10.7B

  upgradeDescription: |
    Upgrade Ollama version to v0.9.2

    # What's Changed
    - Fixed issue where tool calls without parameters would not be returned correctly
    - Fixed does not support generate errors
    - Fixed issue where some special tokens would not be tokenized properly for some model architectures
    - Magistral now supports disabling thinking mode. Note: it is also recommended to change the system prompt when doing so
    - Error messages that previously showed POST predict will now be more informative
    - Improved tool calling reliability for some models
    - Fixed issue on Windows where ollama run would not start Ollama automatically

    Get full release note at: https://github.com/ollama/ollama/releases/tag/v0.9.2