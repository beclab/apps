metadata:
  title: Ollama
  description: Get up and running with large language models.

spec:
  fullDescription: |
    ## IMPORTANT NOTE ##
    This is a shared app. Once installed by the Olares Admin, all users in the cluster can use it through reference app.

    ## OVERVIEW ##
    Ollama is a user-friendly interface for running large language models (LLMs) locally. It is a valuable tool for researchers, developers, and anyone who wants to experiment with language models. With Ollama, you can easily download and run LLMs, customize and create your own, and chat with your LLMs using files on your device.

    Ollama supports a wide range of models, including:
    - Llama 3 8B
    - Llama 3 70B
    - Phi 3 Mini 3.8B
    - Phi 3 Medium 14B
    - Gemma 2 9B
    - Gemma 2 27B
    - Mistral 7B
    - Moondream 2 1.4B
    - Neural Chat 7B
    - Starling 7B
    - Code Llama 7B
    - Llama 2 Uncensored 7B
    - LLaVA 7B
    - Solar 10.7B

  upgradeDescription: |
    Upgrade Ollama version to v0.10.1

    # What's Changed
    - Fixed unicode character input for Japanese and other languages in Ollama's new app
    - Fixed AMD download URL in the logs for ollama serve
    - ollama ps will now show the context length of loaded models
    - Improved performance in gemma3n models by 2-3x
    - Parallel request processing now defaults to 1. For more details, see the FAQ
    - Fixed issue where tool calling would not work correctly with granite3.3 and mistral-nemo models
    - Fixed issue where Ollama's tool calling would not work correctly if a tool's name was part of another one, such as add and get_address
    - Improved performance when using multiple GPUs by 10-30%
    - Ollama's OpenAI-compatible API will now support WebP images
    - Fixed issue where ollama show would report an error
    - ollama run will more gracefully display errors

    Get full release note at: https://github.com/ollama/ollama/releases/tag/v0.10.1
