metadata:
  title: Ollama
  description: 开始使用并运行大型语言模型吧。

spec:
  fullDescription: |
    ## 使用须知 ##
    该应用为共享应用，Olares 管理员安装后，集群中的所有用户都可以通过授权应用程序来调用它。

    ## 应用概览 ##
    Ollama 是一个用于在本地运行大型语言模型（LLMs）的用户友好界面。
    对研究人员、开发者以及任何想要尝试大语言模型的人来说，Ollama 是一个很有价值的工具。使用 Ollama，您可以轻松下载和运行 LLMs，自定义和创建您自己的模型，并使用您设备上的文件与 LLMs 进行对话。

    Ollama 支持广泛的模型，包括：
    - Llama 3 8B
    - Llama 3 70B
    - Phi 3 Mini 3.8B
    - Phi 3 Medium 14B
    - Gemma 2 9B
    - Gemma 2 27B
    - Mistral 7B
    - Moondream 2 1.4B
    - Neural Chat 7B
    - Starling 7B
    - Code Llama 7B
    - Llama 2 Uncensored 7B
    - LLaVA 7B
    - Solar 10.7B

  upgradeDescription: |
    将 Ollama 版本升级至 v0.12.7

    # 新增模型
    - Qwen3-VL：Qwen3-VL 现已支持所有参数规模，范围从 2B 到 235B
    - MiniMax-M2：一个 2300 亿参数的模型，专为编码和智能体工作流而构建，可在 Ollama 云端使用

    # 更新内容
    - 现在，Windows 系统上的模型加载失败信息会更详细
    - 修复了运行 embeddinggemma 时嵌入结果不正确的问题
    - 修复了 Vulkan 后端 gemma3n 的问题
    - 增加了 ROCm 发现设备所需的时间
    - 修复了生成嵌入时出现的截断错误
    - 修复了运行云端模型时的请求状态码
    - 与 OpenAI 兼容的 /v1/embeddings 端点现在支持 encoding_format 参数
    - Ollama 现在会解析不符合 {"name": name, "arguments": args} 格式的工具调用（感谢 @rick-github！）
    - 修复了 Ollama 中的提示处理报告问题运行器
    - 提升模型调度速度
    - 修复了 FROM <model> 无法继承 RENDERER 或 PARSER 命令的问题

    完整版本说明请访问：https://github.com/ollama/ollama/releases/tag/v0.12.7
