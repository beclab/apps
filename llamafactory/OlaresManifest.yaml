olaresManifest.version: '0.8.1'
olaresManifest.type: app
metadata:
  name: llamafactory
  icon: https://file.bttcdn.com/appstore/llamafactory/icon.png
  description: Easily fine-tune 100+ large language models with zero-code CLI and Web UI
  appid: llamafactory
  title: LLaMA Factory
  version: '1.0.4'
  categories:
  - Productivity
entrances:
# - authLevel: private
#   host: llamafactory
#   icon: https://file.bttcdn.com/appstore/llamafactory/icon.png
#   name: llamafactory
#   openMethod: default
#   port: 8000
#   title: llamafactory
#   invisible: true
- authLevel: public
  host: llamafactoryclient
  icon: https://file.bttcdn.com/appstore/llamafactory/icon.png
  name: llamafactoryclient
  openMethod: window
  port: 8080
  title: LLaMA Factory
  # invisible: true
- authLevel: public
  host: llamafactoryclient
  icon: https://file.bttcdn.com/appstore/llamafactory/icon.png
  name: llamafactoryapi
  openMethod: default
  port: 8081
  title: llamafactoryapi
  invisible: true
spec:
  versionName: '0.9.1'
  featuredImage: https://file.bttcdn.com/appstore/llamafactory/1.jpg
  promoteImage:
  - https://file.bttcdn.com/appstore/llamafactory/1.jpg
  - https://file.bttcdn.com/appstore/llamafactory/2.jpg
  - https://file.bttcdn.com/appstore/llamafactory/3.jpg
  fullDescription: |
    ## IMPORTANT NOTE ##
    Please note that this is a cluster-scoped app, you will need the corresponding app to use it.

    ## OVERVIEW ##
    Easily fine-tune 100+ large language models with zero-code CLI and Web UI

    Features
      - **Various models**: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Qwen2-VL, DeepSeek, Yi, Gemma, ChatGLM, Phi, etc.
      - **Integrated methods**: (Continuous) pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO, etc.
      - **Scalable resources**: 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.
      - **Advanced algorithms**: [GaLore](https://github.com/jiaweizzhao/GaLore), [BAdam](https://github.com/Ledzy/BAdam), [APOLLO](https://github.com/zhuhanqing/APOLLO), [Adam-mini](https://github.com/zyushun/Adam-mini), DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ and PiSSA.
      - **Practical tricks**: [FlashAttention-2](https://github.com/Dao-AILab/flash-attention), [Unsloth](https://github.com/unslothai/unsloth), [Liger Kernel](https://github.com/linkedin/Liger-Kernel), RoPE scaling, NEFTune and rsLoRA.
      - **Wide tasks**: Multi-turn dialogue, tool using, image understanding, visual grounding, video recognition, audio understanding, etc.
      - **Experiment monitors**: LlamaBoard, TensorBoard, Wandb, MLflow, SwanLab, etc.
      - **Faster inference**: OpenAI-style API, Gradio UI and CLI with vLLM worker.

      ### Day-N Support for Fine-Tuning Cutting-Edge Models

      | Support Date | Model Name                                                 |
      | ------------ | ---------------------------------------------------------- |
      | Day 0        | Qwen2.5 / Qwen2-VL / QwQ / QvQ / InternLM3 / MiniCPM-o-2.6 |
      | Day 1        | Llama 3 / GLM-4 / Mistral Small / PaliGemma2               |

  developer: llamafactory
  website: https://llamafactory.com/
  sourceCode: https://github.com/llamafactory/llamafactory
  submitter: Olares
  locale:
  - en-US
  - zh-CN
  doc: https://github.com/llamafactory/llamafactory/tree/main/docs
  license:
  - text: MIT
    url: https://github.com/llamafactory/llamafactory#MIT-1-ov-file
  limitedCpu: 6
  requiredCpu: 50m
  requiredDisk: 50Mi
  limitedDisk: 500Gi
  limitedMemory: 21Gi
  requiredMemory: 2Gi
  requiredGpu: 0
  limitedGpu: 16Gi
  supportArch:
  - amd64
  onlyAdmin: true
permission:
  appData: true
  appCache: true
  userData:
  - Home
options:
  apiTimeout: 0
  dependencies:
  - name: olares
    version: '>=1.11.0-0'
    type: system
  appScope:
    clusterScoped: true
    appRef:
    - openwebui
    - perplexica