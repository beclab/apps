olaresManifest.version: '0.8.1'
olaresManifest.type: app
metadata:
  name: llamafactory
  icon: https://file.bttcdn.com/appstore/llamafactory/icon.png
  description: Easily fine-tune 100+ large language models with zero-code CLI and Web UI
  appid: llamafactory
  title: LLaMA Factory
  version: '1.0.5'
  categories:
  - Productivity
entrances:
# - authLevel: private
#   host: llamafactory
#   icon: https://file.bttcdn.com/appstore/llamafactory/icon.png
#   name: llamafactory
#   openMethod: default
#   port: 8000
#   title: llamafactory
#   invisible: true
- authLevel: private
  host: llamafactoryclient
  icon: https://file.bttcdn.com/appstore/llamafactory/icon.png
  name: llamafactoryclient
  openMethod: window
  port: 8080
  title: LLaMA Factory
  # invisible: true
- authLevel: private
  host: llamafactoryclient
  icon: https://file.bttcdn.com/appstore/llamafactory/icon.png
  name: llamafactoryapi
  openMethod: default
  port: 8081
  title: llamafactoryapi
  invisible: true
spec:
  versionName: '0.9.1'
  featuredImage: https://file.bttcdn.com/appstore/llamafactory/1.jpg
  promoteImage:
  - https://file.bttcdn.com/appstore/llamafactory/1.jpg
  - https://file.bttcdn.com/appstore/llamafactory/2.jpg
  - https://file.bttcdn.com/appstore/llamafactory/3.jpg
  - https://file.bttcdn.com/appstore/llamafactory/4.jpg
  fullDescription: |
    ## IMPORTANT NOTE ##
    Please note that this is a cluster-scoped app, you may need the corresponding app to use it.

    ## OVERVIEW ##
    LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It provides a solution for flexibly customizing the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard.

    Features  
    - Various models: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Yi, Gemma, Baichuan, ChatGLM, Phi, etc.
    - Integrated methods: (Continuous) pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO, etc.
    - Scalable resources: 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.
    - Advanced algorithms: GaLore, BAdam, Adam-mini, DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ, PiSSA and Agent tuning.
    - Practical tricks: FlashAttention-2, Unsloth, RoPE scaling, NEFTune and rsLoRA.
    - Experiment monitors: LlamaBoard, TensorBoard, Wandb, MLflow, etc.
    - Faster inference: OpenAI-style API, Gradio UI and CLI with vLLM worker.

  developer: hiyouga
  website: https://github.com/hiyouga/LLaMA-Factory
  sourceCode: https://github.com/hiyouga/LLaMA-Factory
  submitter: Olares
  locale:
  - en-US
  - zh-CN
  doc: https://llamafactory.readthedocs.io/
  license:
  - text: Apache-2.0
    url: https://github.com/hiyouga/LLaMA-Factory?tab=Apache-2.0-1-ov-file#readme
  limitedCpu: 6
  requiredCpu: 50m
  requiredDisk: 50Mi
  limitedDisk: 500Gi
  limitedMemory: 21Gi
  requiredMemory: 2Gi
  requiredGpu: 0
  limitedGpu: 16Gi
  supportArch:
  - amd64
  onlyAdmin: true
permission:
  appData: true
  appCache: true
  userData:
  - Home
options:
  apiTimeout: 0
  dependencies:
  - name: olares
    version: '>=1.11.0-0'
    type: system
  appScope:
    clusterScoped: true
    appRef:
    - openwebui
    - perplexica