olaresManifest.version: '0.10.0'
olaresManifest.type: app
metadata:
  name: llamafactory
  icon: https://file.bttcdn.com/appstore/llamafactory/icon.png
  description: Easily fine-tune 100+ large language models with zero-code CLI and Web UI
  appid: llamafactory
  title: LLaMA Factory
  version: '1.0.8'
  categories:
  - Developer Tools
  - Productivity
entrances:
# - authLevel: private
#   host: llamafactory
#   icon: https://file.bttcdn.com/appstore/llamafactory/icon.png
#   name: llamafactory
#   openMethod: default
#   port: 8000
#   title: llamafactory
#   invisible: true
- authLevel: private
  host: llamafactoryclient
  icon: https://file.bttcdn.com/appstore/llamafactory/icon.png
  name: llamafactoryclient
  openMethod: window
  port: 8080
  title: LLaMA Factory
  # invisible: true
- authLevel: private
  host: llamafactoryclient
  icon: https://file.bttcdn.com/appstore/llamafactory/icon.png
  name: llamafactoryapi
  openMethod: default
  port: 8081
  title: llamafactoryapi
  invisible: true
spec:
  versionName: '0.9.1'
  featuredImage: https://file.bttcdn.com/appstore/llamafactory/1.jpg
  promoteImage:
  - https://file.bttcdn.com/appstore/llamafactory/1.jpg
  - https://file.bttcdn.com/appstore/llamafactory/2.jpg
  - https://file.bttcdn.com/appstore/llamafactory/3.jpg
  - https://file.bttcdn.com/appstore/llamafactory/4.jpg
  fullDescription: |
    LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It provides a solution for flexibly customizing the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard.

    Features  
    - Various models: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Yi, Gemma, Baichuan, ChatGLM, Phi, etc.
    - Integrated methods: (Continuous) pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO, etc.
    - Scalable resources: 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.
    - Advanced algorithms: GaLore, BAdam, Adam-mini, DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ, PiSSA and Agent tuning.
    - Practical tricks: FlashAttention-2, Unsloth, RoPE scaling, NEFTune and rsLoRA.
    - Experiment monitors: LlamaBoard, TensorBoard, Wandb, MLflow, etc.
    - Faster inference: OpenAI-style API, Gradio UI and CLI with vLLM worker.
  upgradeDescription: |
    Update Chart Config
    - Fix app scope
    - Fix GPU inject
  developer: hiyouga
  website: https://github.com/hiyouga/LLaMA-Factory
  sourceCode: https://github.com/hiyouga/LLaMA-Factory
  submitter: Olares
  locale:
  - en-US
  - zh-CN
  doc: https://llamafactory.readthedocs.io/
  license:
  - text: Apache-2.0
    url: https://github.com/hiyouga/LLaMA-Factory?tab=Apache-2.0-1-ov-file#readme
  limitedCpu: 6
  requiredCpu: 50m
  requiredDisk: 50Mi
  limitedDisk: 500Gi
  limitedMemory: 21Gi
  requiredMemory: 2Gi
  requiredGpu: 0
  limitedGpu: 16Gi
  supportArch:
  - amd64
permission:
  appData: true
  appCache: true
  userData:
  - Home
options:
  apiTimeout: 0
  dependencies:
  - name: olares
    version: '>=1.12.1-0'
    type: system

provider:
- name: llamafactoryapi
  entrance: llamafactoryapi
  paths: ["/*"]
  verbs: ["*"]