olaresManifest.version: '0.8.1'
olaresManifest.type: app
metadata:
  name: xinference
  icon: https://file.bttcdn.com/appstore/xinference/icon.png
  description: Model Serving Made Easy
  appid: xinference
  title: Xinference
  version: '1.0.11'
  categories:
  - Productivity
entrances:
# - authLevel: private
#   host: xinference
#   icon: https://file.bttcdn.com/appstore/xinference/icon.png
#   name: xinference
#   openMethod: default
#   port: 8000
#   title: xinference
#   invisible: true
- authLevel: internal
  host: xinferenceclient
  icon: https://file.bttcdn.com/appstore/xinference/icon.png
  name: xinferenceclient
  openMethod: window
  port: 8080
  title: Xinference
  # invisible: true
# - authLevel: public
#   host: xinferenceclient
#   icon: https://file.bttcdn.com/appstore/xinference/icon.png
#   name: xinferenceapi
#   openMethod: default
#   port: 8081
#   title: xinferenceapi
#   invisible: true
spec:
  versionName: '1.2.1'
  featuredImage: https://file.bttcdn.com/appstore/xinference/1.jpg
  promoteImage:
  - https://file.bttcdn.com/appstore/xinference/1.jpg
  - https://file.bttcdn.com/appstore/xinference/2.jpg
  - https://file.bttcdn.com/appstore/xinference/3.jpg    
  fullDescription: |
    ## IMPORTANT NOTE ##
    This is a shared app. Once installed by the Olares Admin, all users in the cluster can use it through reference app.

    ## OVERVIEW ##
    Xorbits Inference(Xinference) is a powerful and versatile library designed to serve language, speech recognition, and multimodal models. With Xorbits Inference, you can effortlessly deploy and serve your or state-of-the-art built-in models using just a single command. Whether you are a researcher, developer, or data scientist, Xorbits Inference empowers you to unleash the full potential of cutting-edge AI models.

    Key Features
    Model Serving Made Easy: Simplify the process of serving large language, speech recognition, and multimodal models. You can set up and deploy your models for experimentation and production with a single command.

    State-of-the-Art Models: Experiment with cutting-edge built-in models using a single command. Inference provides access to state-of-the-art open-source models!

    Heterogeneous Hardware Utilization: Make the most of your hardware resources with ggml. Xorbits Inference intelligently utilizes heterogeneous hardware, including GPUs and CPUs, to accelerate your model inference tasks.

    Flexible API and Interfaces: Offer multiple interfaces for interacting with your models, supporting OpenAI compatible RESTful API (including Function Calling API), RPC, CLI and WebUI for seamless model management and interaction.

    Distributed Deployment: Excel in distributed deployment scenarios, allowing the seamless distribution of model inference across multiple devices or machines.

    Built-in Integration with Third-Party Libraries: Xorbits Inference seamlessly integrates with popular third-party libraries including LangChain, LlamaIndex, Dify, and Chatbox.

  upgradeDescription: |
    Update Chart Config
    - Fix GPU inject
        
  developer: Xorbits Inc.
  website: https://xinference.com/
  sourceCode: https://github.com/xinference/xinference
  submitter: Olares
  locale:
  - en-US
  - zh-CN
  doc: https://inference.readthedocs.io/en/latest/user_guide/index.html
  license:
  - text: Apache-2.0
    url: https://github.com/xorbitsai/inference#Apache-2.0-1-ov-file
  limitedCpu: 6
  requiredCpu: 50m
  requiredDisk: 50Mi
  limitedDisk: 500Gi
  limitedMemory: 21Gi
  requiredMemory: 2Gi
  requiredGpu: 0
  limitedGpu: 16Gi
  supportArch:
  - amd64
  onlyAdmin: true
permission:
  appData: true
  appCache: true
options:
  apiTimeout: 0
  dependencies:
  - name: olares
    version: '>=1.11.0-0'
    type: system
  appScope:
    clusterScoped: true
    appRef:
    - openwebui
    - perplexica
    - n8n
    - ragflow
    - lobechat
    - dify    