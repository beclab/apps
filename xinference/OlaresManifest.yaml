olaresManifest.version: '0.8.1'
olaresManifest.type: app
metadata:
  name: xinference
  icon: https://file.bttcdn.com/appstore/xinference/icon.png
  description: Get up and running with large language models.
  appid: xinference
  title: xinference
  version: '1.0.8'
  categories:
  - Productivity
entrances:
# - authLevel: private
#   host: xinference
#   icon: https://file.bttcdn.com/appstore/xinference/icon.png
#   name: xinference
#   openMethod: default
#   port: 8000
#   title: xinference
#   invisible: true
- authLevel: public
  host: xinferenceclient
  icon: https://file.bttcdn.com/appstore/xinference/icon.png
  name: xinferenceclient
  openMethod: window
  port: 8080
  title: xinference
  # invisible: true
# - authLevel: public
#   host: xinferenceclient
#   icon: https://file.bttcdn.com/appstore/xinference/icon.png
#   name: xinferenceapi
#   openMethod: default
#   port: 8081
#   title: xinferenceapi
#   invisible: true
spec:
  versionName: '0.5.2'
  featuredImage: https://file.bttcdn.com/appstore/xinference/1.webp
  promoteImage:
  - https://file.bttcdn.com/appstore/xinference/1.webp
  - https://file.bttcdn.com/appstore/xinference/2.webp
  - https://file.bttcdn.com/appstore/xinference/3.webp
  fullDescription: |
    ## IMPORTANT NOTE ##
    Please note that this is a cluster-scoped app, you will need the corresponding app to use it.

    ## OVERVIEW ##
    xinference is a user-friendly interface for running large language models (LLMs) locally. It is a valuable tool for researchers, developers, and anyone who wants to experiment with language models. With xinference, you can easily download and run LLMs, customize and create your own, and chat with your LLMs using files on your device.

    xinference supports a wide range of models, including:
    - Llama 3	8B
    - Llama 3	70B
    - Phi 3 Mini	3.8B
    - Phi 3 Medium	14B
    - Gemma 2	9B
    - Gemma 2	27B
    - Mistral	7B
    - Moondream 2	1.4B
    - Neural Chat	7B
    - Starling	7B
    - Code Llama	7B
    - Llama 2 Uncensored	7B
    - LLaVA	7B
    - Solar	10.7B

  upgradeDescription: |
    Upgrade App Version to v0.5.2

    # New models
    EXAONE 3.5: a collection of instruction-tuned bilingual (English and Korean) generative models ranging from 2.4B to 32B parameters, developed and released by LG AI Research.

    # What's Changed
    Fixed issue where whitespace would get trimmed from prompt when images were provided
    Improved memory estimation when scheduling models
    xinference_ORIGINS will now check hosts in a case insensitive manner

    Get full release note at: https://github.com/xinference/xinference/releases/tag/v0.5.2
    
  developer: xinference
  website: https://xinference.com/
  sourceCode: https://github.com/xinference/xinference
  submitter: Olares
  locale:
  - en-US
  - zh-CN
  doc: https://github.com/xinference/xinference/tree/main/docs
  license:
  - text: MIT
    url: https://github.com/xinference/xinference#MIT-1-ov-file
  limitedCpu: 6
  requiredCpu: 50m
  requiredDisk: 50Mi
  limitedDisk: 500Gi
  limitedMemory: 21Gi
  requiredMemory: 2Gi
  requiredGpu: 0
  limitedGpu: 16Gi
  supportArch:
  - amd64
  onlyAdmin: true
permission:
  appData: true
  appCache: true
options:
  apiTimeout: 0
  dependencies:
  - name: olares
    version: '>=1.11.0-0'
    type: system
  appScope:
    clusterScoped: true
    appRef:
    - openwebui
    - perplexica