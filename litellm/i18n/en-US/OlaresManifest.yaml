metadata:
  description: Call 100+ LLMs in OpenAI format
  title: LiteLLM
spec:
  fullDescription: |
    LiteLLM is a Python SDK and Proxy Server (AI Gateway) to call 100+ LLM APIs in OpenAI (or native) format, with cost tracking, guardrails, loadbalancing and logging.

    Features:
    - Unified API: Call 100+ LLM APIs (OpenAI, Anthropic, Azure, Bedrock, VertexAI, etc.) in OpenAI format
    - Cost Tracking: Track costs across all providers
    - Load Balancing: Distribute requests across multiple models/endpoints
    - Guardrails: Content filtering and safety checks
    - Logging & Observability: Comprehensive logging and monitoring
    - Rate Limiting: Built-in rate limiting and throttling
    - Proxy Server: Deploy as an AI Gateway/Proxy server
    - Multi-tenant: Support for multiple users and teams
