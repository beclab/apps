---
olaresManifest.version: "0.10.0"
olaresManifest.type: app
apiVersion: 'v2'
metadata:
  name: ollamav2
  icon: https://app.cdn.olares.com/appstore/ollama/icon.png
  description: Get up and running with large language models.
  appid: ollamav2
  title: Ollama
  version: "1.0.10"
  categories:
    - Utilities_v112
    - Productivity

sharedEntrances:
  - name: ollamav2
    host: sharedentrances-ollama
    port: 0
    title: Ollama API
    icon: https://app.cdn.olares.com/appstore/ollama/icon.png
    invisible: true
    authLevel: internal
entrances:
  - name: terminal
    port: 8081
    host: terminalclient
    title: Ollama
    icon: https://app.cdn.olares.com/appstore/ollama/icon.png
    openMethod: window
  - authLevel: internal
    host: ollamaclient
    icon: https://app.cdn.olares.com/appstore/ollama/icon.png
    name: ollamaclient
    openMethod: window
    port: 8080
    title: Ollama API
    invisible: true

spec:
  versionName: "0.15.2"
  featuredImage: https://app.cdn.olares.com/appstore/ollama/1.webp
  promoteImage:
    - https://app.cdn.olares.com/appstore/ollama/1.webp
    - https://app.cdn.olares.com/appstore/ollama/2.webp
    - https://app.cdn.olares.com/appstore/ollama/3.webp

  fullDescription: |
    ## IMPORTANT NOTE ##
    This is a shared app. Once installed by the Olares Admin, all users in the cluster can use it through reference app.

    ## OVERVIEW ##
    Ollama is a user-friendly interface for running large language models (LLMs) locally. It is a valuable tool for researchers, developers, and anyone who wants to experiment with language models. With Ollama, you can easily download and run LLMs, customize and create your own models, and chat with your LLMs using files on your device.

    Ollama supports a wide range of models, including:
    - Llama 3 8B
    - Llama 3 70B
    - Phi 3 Mini 3.8B
    - Phi 3 Medium 14B
    - Gemma 2 9B
    - Gemma 2 27B
    - Mistral 7B
    - Moondream 2 1.4B
    - Neural Chat 7B
    - Starling 7B
    - Code Llama 7B
    - Llama 2 Uncensored 7B
    - LLaVA 7B
    - Solar 10.7B

  upgradeDescription: |
    Upgrade Ollama version from v0.13.5 to v0.15.2

    ## What's Changed

    # v0.15.2 (2026-01-27)
    - New `ollama launch clawdbot` command for launching Clawdbot using Ollama models

    # v0.15.1
    - Bug fixes and stability improvements
    - Performance optimizations
    - Enhanced model compatibility

    # v0.15.0
    - Major version update with enhanced features
    - Improved model support and architecture
    - API improvements and stability enhancements

    # v0.14.3 (2026-01-16)
    - New Models: GLM-4.7-Flash (30B class model), LFM2.5-1.2B-Thinking (hybrid models for on-device deployment)
    - Image generation models: Z-Image Turbo (6B), Flux.2 Klein
    - Fixed issue where Ollama's macOS app would interrupt system shutdown
    - Fixed `ollama create` and `ollama show` commands for experimental models
    - The `/api/generate` API can now be used for image generation
    - Fixed minor issues in Nemotron-3-Nano tool parsing
    - Fixed issue where removing an image generation model would cause it to first load
    - Fixed issue where `ollama rm` would only stop the first model in the list if it were running

    # v0.14.2 (2026-01-16)
    - New Models: TranslateGemma (open translation models built on Gemma 3, supporting 55 languages)
    - Shift + Enter (or Ctrl + j) will now enter a newline in Ollama's CLI
    - Improved `/v1/responses` API to better conform to OpenResponses specification

    # v0.14.1
    - Fixed auto-update signature verification failure
    - Bug fixes and stability improvements

    # v0.14.0
    - Initial v0.14 release with enhanced features and improvements

    For detailed release notes including new models and features in each version, please visit:
    https://github.com/ollama/ollama/releases

  developer: ollama
  website: https://ollama.com/
  sourceCode: https://github.com/ollama/ollama
  submitter: Olares
  locale:
    - en-US
    - zh-CN
  doc: https://github.com/ollama/ollama/tree/main/docs
  license:
    - text: MIT
      url: https://github.com/ollama/ollama#MIT-1-ov-file
  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
  limitedCpu: "7"
  requiredCpu: 150m
  requiredDisk: 50Mi
  limitedDisk: 500Gi
  limitedMemory: 40Gi
  requiredMemory: 5Gi
  requiredGpu: 0
  limitedGpu: 16Gi
  {{- else }}
  requiredMemory: 64Mi
  limitedMemory: 800Mi
  requiredDisk: 50Mi
  limitedDisk: 200Mi
  requiredCpu: 10m
  limitedCpu: 800m
  {{- end }}

  supportArch:
    - amd64
    - arm64
  onlyAdmin: false
  subCharts:
  - name: ollamaserver
    shared: true
  - name: ollamav2
permission:
  appData: true
  appCache: true

options:
  apiTimeout: 0
  appScope:
  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
    clusterScoped: true
    appRef:
      - ollamav2
  {{- else }}
  clusterScoped: false
  {{- end }}
  dependencies:
    - name: olares
      version: '>=1.12.3-0'
      type: system
  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
  {{- else }}
    - name: ollamav2
      type: application
      version: '>=1.0.1'
      mandatory: true
  {{- end }}