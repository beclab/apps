olaresManifest.version: '0.10.0'
olaresManifest.type: app
metadata:
  name: langfuse
  icon: https://file.bttcdn.com/appstore/langfuse/icon.png
  description: Open source LLM engineering platform
  appid: langfuse
  title: Langfuse
  version: '1.0.0'
  categories:
  - Productivity
  - Productivity_v112
entrances:
  - name: langfuse
    host: langfuse-web
    port: 3000
    icon: https://file.bttcdn.com/appstore/langfuse/icon.png
    title: Langfuse
    authLevel: internal
    openMethod: window
spec:
  versionName: '3.103.0'
  fullDescription: |
    Langfuse is an open source LLM engineering platform. It helps teams collaboratively develop, monitor, evaluate, and debug AI applications. Langfuse can be self-hosted in minutes and is battle-tested.

    Core Features
    LLM Application Observability: Instrument your app and start ingesting traces to Langfuse, thereby tracking LLM calls and other relevant logic in your app such as retrieval, embedding, or agent actions. Inspect and debug complex logs and user sessions.

    Prompt Management helps you centrally manage, version control, and collaboratively iterate on your prompts. Thanks to strong caching on server and client side, you can iterate on prompts without adding latency to your application.

    Evaluations are key to the LLM application development workflow, and Langfuse adapts to your needs. It supports LLM-as-a-judge, user feedback collection, manual labeling, and custom evaluation pipelines via APIs/SDKs.

    Datasets enable test sets and benchmarks for evaluating your LLM application. They support continuous improvement, pre-deployment testing, structured experiments, flexible evaluation, and seamless integration with frameworks like LangChain and LlamaIndex.

    LLM Playground is a tool for testing and iterating on your prompts and model configurations, shortening the feedback loop and accelerating development. When you see a bad result in tracing, you can directly jump to the playground to iterate on it.

    Comprehensive API: Langfuse is frequently used to power bespoke LLMOps workflows while using the building blocks provided by Langfuse via the API. OpenAPI spec, Postman collection, and typed SDKs for Python, JS/TS are available.
  developer: Langfuse GmbH
  website: https://langfuse.com
  sourceCode: https://github.com/langfuse/langfuse
  submitter: Olares
  locale:
    - en-US
    - zh-CN
  doc: https://langfuse.com/docs
  license:
    - text: Langfuse GmbH
      url: https://github.com/langfuse/langfuse?tab=License-1-ov-file
  requiredMemory: 2Gi
  requiredDisk: 50Mi
  requiredCpu: 1
  limitedMemory: 12Gi
  limitedCpu: 8
  supportArch:
    - amd64
    - arm64
permission:
  appData: true
  appCache: true
  userData:
    - Home
  sysData:
    - dataType: legacy_ollama
      appName: ollama
      svc: ollama
      port: 11434
      group: api.ollama
      version: v2
      ops:
        - All
options:
  apiTimeout: 0
  allowedOutboundPorts:
    - 465
    - 587
  dependencies:
    - name: olares
      version: '>=1.11.6-0'
      type: system
middleware:
  postgres:
    username: langfuse
    databases:
    - name: langfuse