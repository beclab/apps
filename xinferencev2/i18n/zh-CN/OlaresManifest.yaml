metadata:
  description: 模型服务轻松搞定
  title: Xinference
spec:
  fullDescription: |
    ## 使用须知 ##
    该应用为共享应用，Olares 管理员安装后，集群中的所有用户都可以通过授权应用程序来调用它。

    ## 应用概览 ##
    Xorbits Inference（Xinference）是一个功能强大、用途广泛的库，设计用于提供语言、语音识别和多模态模型。有了 Xorbits Inference，你只需使用一条命令，就能毫不费力地部署和提供你的或最先进的内置模型。无论您是研究人员、开发人员还是数据科学家，Xorbits Inference 都能让您充分释放尖端人工智能模型的潜力。

    主要功能
    轻松提供模型：简化提供大型语言、语音识别和多模态模型的流程。只需一条命令，您就可以设置和部署模型，用于实验和生产。

    最先进的模型： 只需使用一条命令，即可使用最先进的内置模型进行实验。Inference 可提供最先进的开源模型！

    异构硬件利用： 利用 ggml 充分利用硬件资源。Xorbits Inference 可智能地利用异构硬件（包括 GPU 和 CPU）来加速模型推理任务。

    灵活的 API 和接口： 提供与模型交互的多种接口，支持与 OpenAI 兼容的 RESTful API（包括函数调用 API）、RPC、CLI 和 WebUI，实现无缝模型管理和交互。

    分布式部署： 在分布式部署场景中表现出色，允许在多个设备或机器上无缝分配模型推理。

    与第三方库的内置集成： Xorbits Inference 与流行的第三方库无缝集成，包括 LangChain、LlamaIndex、Dify 和 Chatbox。
  upgradeDescription: |
    ## Xinference v2.0.0 升级说明
    
    ### 新增功能
    - 新增多个模型支持：
      * Qwen3-VL-Embedding-2B/8B（嵌入模型）
      * Qwen3-VL-Reranker-2B/8B（重排序模型）
      * MinerU2.5-2509-1.2B（OCR模型）
      * GLM-4.6（大语言模型）
      * Z-Image（图像模型）
    - 添加视频 GGUF 缓存管理功能
    - 支持 chat_template.jinja 模板
    - UI 改进：使用浏览器语言作为默认语言，添加官网和模型中心链接
    
    ### 性能优化
    - 增加 Nginx 代理超时配置，解决模型启动时的 504 超时问题
      * proxy_send_timeout: 60s → 3600s
      * proxy_read_timeout: 1800s → 3600s
      * proxy_connect_timeout: 60s → 300s
    - LLM 缓存配置优化，跳过不必要的下载
    
    ### Bug 修复
    - 修复 transformers 版本兼容性问题（< 5.0.0）
    - 修复缓存管理器下载时的阻塞问题
    - 修复多个已知问题
    
    ### 参考链接
    - 发布说明: https://github.com/xorbitsai/inference/releases/tag/v2.0.0