---
olaresManifest.version: '0.10.0'
olaresManifest.type: app
apiVersion: 'v2'
metadata:
  name: xinferencev2
  icon: https://app.cdn.olares.com/appstore/xinference/icon.png
  description: Model Serving Made Easy
  appid: xinferencev2
  title: Xinference
  version: '1.0.5'
  categories:
  - Utilities_v112
  - Productivity
sharedEntrances:
- name: xinferencev2
  title: Xinference
  host: sharedentrances-api
  icon: https://app.cdn.olares.com/appstore/xinference/icon.png
  port: 0
  invisible: true
  authLevel: internal
entrances:
# - authLevel: private
#   host: xinference
#   icon: https://app.cdn.olares.com/appstore/xinference/icon.png
#   name: xinference
#   openMethod: default
#   port: 8000
#   title: xinference
#   invisible: true
- authLevel: internal
  host: xinferenceclient
  icon: https://app.cdn.olares.com/appstore/xinference/icon.png
  name: xinferenceclient
  openMethod: window
  port: 8080
  title: Xinference
  # invisible: true
# - authLevel: public
#   host: xinferenceclient
#   icon: https://app.cdn.olares.com/appstore/xinference/icon.png
#   name: xinferenceapi
#   openMethod: default
#   port: 8081
#   title: xinferenceapi
#   invisible: true
spec:
  versionName: '2.0.0'
  featuredImage: https://app.cdn.olares.com/appstore/xinference/1.jpg
  promoteImage:
  - https://app.cdn.olares.com/appstore/xinference/1.jpg
  - https://app.cdn.olares.com/appstore/xinference/2.jpg
  - https://app.cdn.olares.com/appstore/xinference/3.jpg    
  fullDescription: |
    ## IMPORTANT NOTE ##
    This is a shared app. Once installed by the Olares Admin, all users in the cluster can use it through reference app.

    ## OVERVIEW ##
    Xorbits Inference(Xinference) is a powerful and versatile library designed to serve language, speech recognition, and multimodal models. With Xorbits Inference, you can effortlessly deploy and serve your or state-of-the-art built-in models using just a single command. Whether you are a researcher, developer, or data scientist, Xorbits Inference empowers you to unleash the full potential of cutting-edge AI models.

    Key Features
    Model Serving Made Easy: Simplify the process of serving large language, speech recognition, and multimodal models. You can set up and deploy your models for experimentation and production with a single command.

    State-of-the-Art Models: Experiment with cutting-edge built-in models using a single command. Inference provides access to state-of-the-art open-source models!

    Heterogeneous Hardware Utilization: Make the most of your hardware resources with ggml. Xorbits Inference intelligently utilizes heterogeneous hardware, including GPUs and CPUs, to accelerate your model inference tasks.

    Flexible API and Interfaces: Offer multiple interfaces for interacting with your models, supporting OpenAI compatible RESTful API (including Function Calling API), RPC, CLI and WebUI for seamless model management and interaction.

    Distributed Deployment: Excel in distributed deployment scenarios, allowing the seamless distribution of model inference across multiple devices or machines.

    Built-in Integration with Third-Party Libraries: Xorbits Inference seamlessly integrates with popular third-party libraries including LangChain, LlamaIndex, Dify, and Chatbox.

  upgradeDescription: |
    ## Xinference v2.0.0 升级说明
    
    ### 新增功能
    - 新增多个模型支持：
      * Qwen3-VL-Embedding-2B/8B（嵌入模型）
      * Qwen3-VL-Reranker-2B/8B（重排序模型）
      * MinerU2.5-2509-1.2B（OCR模型）
      * GLM-4.6（大语言模型）
      * Z-Image（图像模型）
    - 添加视频 GGUF 缓存管理功能
    - 支持 chat_template.jinja 模板
    - UI 改进：使用浏览器语言作为默认语言，添加官网和模型中心链接
    
    ### 性能优化
    - 增加 Nginx 代理超时配置，解决模型启动时的 504 超时问题
      * proxy_send_timeout: 60s → 3600s
      * proxy_read_timeout: 1800s → 3600s
      * proxy_connect_timeout: 60s → 300s
    - LLM 缓存配置优化，跳过不必要的下载
    
    ### Bug 修复
    - 修复 transformers 版本兼容性问题（< 5.0.0）
    - 修复缓存管理器下载时的阻塞问题
    - 修复多个已知问题
    
    ### 参考链接
    - 发布说明: https://github.com/xorbitsai/inference/releases/tag/v2.0.0
        
  developer: Xorbits Inc.
  website: https://xinference.com/
  sourceCode: https://github.com/xinference/xinference
  submitter: Olares
  locale:
  - en-US
  - zh-CN
  doc: https://inference.readthedocs.io/en/latest/user_guide/index.html
  license:
  - text: Apache-2.0
    url: https://github.com/xorbitsai/inference#Apache-2.0-1-ov-file
  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
  limitedCpu: 6
  requiredCpu: 50m
  requiredDisk: 50Mi
  limitedDisk: 500Gi
  limitedMemory: 21Gi
  requiredMemory: 2Gi
  requiredGpu: 4
  limitedGpu: 22Gi
  {{- else }}
  requiredMemory: 64Mi
  limitedMemory: 256Mi
  requiredDisk: 1Mi
  limitedDisk: 100Mi
  requiredCpu: 10m
  limitedCpu: 100m
  {{- end }}
  supportArch:
  - amd64
  subCharts:
  - name: xinferencev2server
    shared: true
  - name: xinferencev2
permission:
  appData: true
  appCache: true
options:
  apiTimeout: 0
  dependencies:
  - name: olares
    version: '>=1.12.3-0'
    type: system
{{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
{{- else }}
  - name: xinferencev2
    type: application
    version: '>=1.0.1'
    mandatory: true
{{- end }}    
  appScope:
{{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
    clusterScoped: true
    appRef:
    - xinferencev2
{{- else }}
    clusterScoped: false
{{- end }}

envs:
  - envName: OLARES_USER_HUGGINGFACE_SERVICE
    required: true
    applyOnChange: true
    valueFrom:
      envName: OLARES_USER_HUGGINGFACE_SERVICE