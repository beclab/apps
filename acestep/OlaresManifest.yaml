olaresManifest.version: '0.9.0'
olaresManifest.type: app
metadata:
  name: acestep
  description: A Step Towards Music Generation Foundation Model.
  icon: https://file.bttcdn.com/appstore/acestep/icon.png
  appid: acestep
  version: '1.0.2'
  title: ACE-Step
  categories:
  - Utilities
entrances:
- name: acestep
  port: 8080
  host: acestep-web-svc
  title: ACE-Step
  icon: https://file.bttcdn.com/appstore/acestep/icon.png
  authLevel: internal
  openMethod: window
permission:
  appData: true
  appCache: true
  userData:
  - Home
spec:
  versionName: '1.0.5'
  fullDescription: |    
    ACE-Step is a novel open-source foundation model for music generation that overcomes key limitations of existing approaches and achieves state-of-the-art performance through a holistic architectural design.

    ## Features ##
    Diverse Styles & Genres
    - Supports all mainstream music styles with various description formats including short tags, descriptive text, or use-case scenarios
    - Capable of generating music across different genres with appropriate instrumentation and style

    Multiple Languages
    - Supports 19 languages with top 10 well-performing languages including: English, Chinese, Russian, Spanish, Japanese, German, French, Portuguese, Italian, Korean
    - Due to data imbalance, less common languages may underperform

    Instrumental Styles
    - Supports various instrumental music generation across different genres and styles
    - Capable of producing realistic instrumental tracks with appropriate timbre and expression for each instrument
    - Can generate complex arrangements with multiple instruments while maintaining musical coherence

    Vocal Techniques
    - Capable of rendering various vocal styles and techniques with good quality
    - Supports different vocal expressions including various singing techniques and styles

    Variations Generation
    - Implemented using training-free, inference-time optimization techniques
    - Flow-matching model generates initial noise, then uses trigFlow's noise formula to add additional Gaussian noise
    - Adjustable mixing ratio between original initial noise and new Gaussian noise to control variation degree

    Repainting
    - Implemented by adding noise to the target audio input and applying mask constraints during the ODE process
    - When input conditions change from the original generation, only specific aspects can be modified while preserving the rest
    - Can be combined with Variations Generation techniques to create localized variations in style, lyrics, or vocals

    Lyric Editing

    - Innovatively applies flow-edit technology to enable localized lyric modifications while preserving melody, vocals, and accompaniment
    - Works with both generated content and uploaded audio, greatly enhancing creative possibilities
    - Current limitation: can only modify small segments of lyrics at once to avoid distortion, but multiple edits can be applied sequentially

    Lyric2Vocal (LoRA)
    - Based on a LoRA fine-tuned on pure vocal data, allowing direct generation of vocal samples from lyrics
    - Offers numerous practical applications such as vocal demos, guide tracks, songwriting assistance, and vocal arrangement experimentation
    - Provides a quick way to test how lyrics might sound when sung, helping songwriters iterate faster

    Text2Samples (LoRA)
    - Similar to Lyric2Vocal, but fine-tuned on pure instrumental and sample data
    - Capable of generating conceptual music production samples from text descriptions
    - Useful for quickly creating instrument loops, sound effects, and musical elements for production

    ## Coming Soon ##
    RapMachine
    - Fine-tuned on pure rap data to create an AI system specialized in rap generation
    - Expected capabilities include AI rap battles and narrative expression through rap
    - Rap has exceptional storytelling and expressive capabilities, offering extraordinary application potential

    StemGen
    - A controlnet-lora trained on multi-track data to generate individual instrument stems
    - Takes a reference track and specified instrument (or instrument reference audio) as input
    - Outputs an instrument stem that complements the reference track, such as creating a piano accompaniment for a flute melody or adding jazz drums to a lead guitar

    Singing2Accompaniment
    - The reverse process of StemGen, generating a mixed master track from a single vocal track
    - Takes a vocal track and specified style as input to produce a complete vocal accompaniment
    - Creates full instrumental backing that complements the input vocals, making it easy to add professional-sounding accompaniment to any vocal recording
  developer: ace-step
  website: https://ace-step.github.io/
  sourceCode: https://github.com/ace-step/ACE-Step
  submitter: Olares
  locale:
  - en-US
  - zh-CN
  doc: https://ace-step.github.io/
  license:
  - text: Apache-2.0 License
    url: https://github.com/ace-step/ACE-Step?tab=Apache-2.0-1-ov-file
  requiredMemory: 3Gi
  limitedMemory: 18Gi
  requiredDisk: 10Gi
  limitedDisk: 100Gi
  requiredCpu: 1
  limitedCpu: 5
  requiredGpu: 5Gi
  limitedGpu: 16Gi  
  supportArch:
  - amd64
options:
  apiTimeout: 0  
  dependencies:
  - name: olares
    type: system
    version: '>=1.12.0-0'