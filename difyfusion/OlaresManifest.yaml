olaresManifest.version: '0.8.1'
olaresManifest.type: app
metadata:
  name: difyfusion
  description: The Innovation Engine for GenAI Applications
  icon: https://file.bttcdn.com/appstore/dify/icon.png
  version: '1.0.7'
  title: Dify For Cluster
  categories:
  - Productivity
permission:
  appData: true
  appCache: true
  sysData:
  - dataType: legacy_ollama
    appName: ollama
    svc: ollama
    port: 11434
    group: api.ollama
    version: v2
    ops:
    - All
  - dataType: legacy_gaianetai
    appName: gaianetai
    svc: gaianetai
    port: 8080
    group: api.gaianetai
    version: v2
    ops:
    - All
  - dataType: legacy_whisper
    appName: whisper
    svc: whisper
    port: 8000
    group: api.whisper
    version: v2
    ops:
    - All
  - dataType: legacy_openedaispeech
    appName: openedaispeech
    svc: openedaispeech
    port: 8000
    group: api.openedaispeech
    version: v2
    ops:
    - All
  - dataType: legacy_sdwebui
    appName: sdwebui
    svc: sdwebui
    port: 7860
    group: api.sdwebui
    version: v2
    ops:
    - All
spec:
  namespace: user-space
  versionName: '0.15.3'
  onlyAdmin: true
  fullDescription: |
    ## IMPORTANT NOTE ##
    This Dify application only supports up to Olares version 1.11 and will not be updated further unless there are critical security updates. Systems running version 1.12 or above will no longer support this version. If you need to use the latest version of Dify, please install the Dify Shared.

    This Dify application has been integrated with Olares OS services. It allows Dify to use Olares SSO for user authentication.
    
    Please note that this is a cluster-scoped app, you will need the corresponding client app to use it.

    ## OVERVIEW ##
    Dify is an open-source LLM app development platform. Its intuitive interface combines AI workflow, RAG pipeline, agent capabilities, model management, observability features and more, letting you quickly go from prototype to production. Here's a list of the core features:

    1. Workflow: Build and test powerful AI workflows on a visual canvas, leveraging all the following features and beyond.

    2. Comprehensive model support: Seamless integration with hundreds of proprietary / open-source LLMs from dozens of inference providers and self-hosted solutions, covering GPT, Mistral, Llama3, and any OpenAI API-compatible models. A full list of supported model providers can be found here.

    3. Prompt IDE: Intuitive interface for crafting prompts, comparing model performance, and adding additional features such as text-to-speech to a chat-based app.

    4. RAG Pipeline: Extensive RAG capabilities that cover everything from document ingestion to retrieval, with out-of-box support for text extraction from PDFs, PPTs, and other common document formats.

    5. Agent capabilities: You can define agents based on LLM Function Calling or ReAct, and add pre-built or custom tools for the agent. Dify provides 50+ built-in tools for AI agents, such as Google Search, DELL·E, Stable Diffusion and WolframAlpha.

    6. LLMOps: Monitor and analyze application logs and performance over time. You could continuously improve prompts, datasets, and models based on production data and annotations.

    7. Backend-as-a-Service: All of Dify's offerings come with corresponding APIs, so you could effortlessly integrate Dify into your own business logic.
  upgradeDescription: |
    What's New in v0.15.3?

    Hey folks, it's time for another update, and we've got some exciting additions and improvements rolling out with version v0.15.3. Let’s dive into the highlights:

    New Model Support
    - DeepSeek Models: DeepSeek R1 is now supported across several platforms, including SiliconFlow, Azure AI Foundry, Ollama, Volcengine, OpenRouter, Nvidia Catalog, and more. This opens up new possibilities for leveraging AI reasoning and insights across diverse environments.

    - Gemini 2.0 Series: Introducing the latest models in the Gemini 2.0 series, such as Gemini 2.0 Flash 001 and Gemini 2.0 Pro Exp. These models deliver exceptional performance and efficiency, perfect for high-precision, fast-processing tasks.

    Enhancements
    - Firecrawl Upgrade: Updated to the v1 API by @ftonato, providing improved performance and more refined results.

    - GLM-4-AIR-0111 Support: Dive into advanced natural language processing tasks more effectively with this addition by @Jhvcc.

    - Agent Thinking Content Display: Visualize agent thinking paths with DeepSeek’s R1 model, providing better understanding and debugging capabilities, courtesy of @hjlarry.

    Bug Fixes
    - SSRF Proxy File Descriptor Leak Fix: Eliminated file descriptor leaks to enhance performance in concurrent environments, thanks to @ZuzooVn.

    - Page Crash on String Variable Property Access: Resolved issues where improper string handling could cause unintentional crashes, fixed by @iamjoel.

    Keep exploring and integrating these new capabilities into your workflows. As always, happy building, and we look forward to hearing how you leverage these updates in your projects!

    View full release note at: https://github.com/langgenius/dify/releases/tag/0.15.3

  developer: LangGenius
  website: https://dify.ai/
  locale:
  - en-US
  - zh-CN
  sourceCode: https://github.com/langgenius/dify
  submitter: Olares
  doc: https://github.com/langgenius/dify#readme
  license:
  - text: Apache-2.0
    url: https://github.com/langgenius/dify?tab=License-1-ov-file#readme
  requiredMemory: 32Mi
  limitedMemory: 80Gi
  requiredDisk: 512Mi
  limitedDisk: 50Gi
  requiredCpu: 100m
  limitedCpu: 200000m
  supportArch:
  - amd64
  - arm64
options:
  dependencies:
  - name: olares
    type: system
    version: '>=1.10.1-0, <1.12.0-0'
  appScope:
    clusterScoped: true
    appRef:
    - difyfusionclient
  conflicts:
  - name: dify
    type: application
entrances:
- name: difyfusion
  port: 5001
  host: difyfusion
  title: Dify For Cluster
  icon: https://file.bttcdn.com/appstore/dify/icon.png
  invisible: true
